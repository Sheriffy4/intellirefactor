#!/usr/bin/env python3
"""
Refactoring Final Reporter - Thin wrapper for intellirefactor.orchestration.refactoring_reporter

This is a deprecated wrapper. Please use intellirefactor.orchestration.RefineryReporter directly.
"""

import warnings
from intellirefactor.orchestration.refactoring_reporter import *

warnings.warn(
    "refactoring_reporter.py is deprecated; use intellirefactor.orchestration.RefineryReporter",
    DeprecationWarning,
    stacklevel=2,
)


@dataclass
class RefactoringStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞."""

    garbage_files_found: int = 0
    garbage_files_moved: int = 0
    size_freed_bytes: int = 0
    directories_analyzed: int = 0
    entry_points_found: int = 0
    config_files_found: int = 0
    modules_analyzed: int = 0
    categories_found: int = 0
    documents_created: int = 0


class RefactoringReporter:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–µ."""

    def __init__(self, project_root: Path = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–ø–æ—Ä—Ç–µ—Ä–∞.

        Args:
            project_root: –ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
        """
        self.project_root = project_root or Path.cwd()
        self.stats = RefactoringStats()

    def generate_report(self) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –æ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–µ.

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç—á–µ—Ç–∞
        """
        report = {
            "timestamp": datetime.now().isoformat(),
            "project_root": str(self.project_root),
            "stats": {},
            "documents": {},
            "cleanup": {},
            "validation": {},
            "summary": {},
        }

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—á–∏—Å—Ç–∫–∏
        self._analyze_cleanup_results(report)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        self._analyze_created_documents(report)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
        self._analyze_project_structure(report)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–µ—Å—Ç—Ä –º–æ–¥—É–ª–µ–π
        self._analyze_module_registry(report)

        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É
        self._create_summary(report)

        return report

    def _analyze_cleanup_results(self, report: Dict[str, Any]) -> None:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—á–∏—Å—Ç–∫–∏ –º—É—Å–æ—Ä–∞."""
        to_delete_path = self.project_root / "_to_delete"

        cleanup_data = {
            "to_delete_exists": to_delete_path.exists(),
            "moved_files": 0,
            "categories": {},
            "total_size": 0,
        }

        if to_delete_path.exists():
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–µ—Ä–µ–º–µ—â–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            moved_files = list(to_delete_path.rglob("*"))
            moved_files = [f for f in moved_files if f.is_file()]
            cleanup_data["moved_files"] = len(moved_files)

            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
            total_size = sum(f.stat().st_size for f in moved_files if f.exists())
            cleanup_data["total_size"] = total_size
            self.stats.size_freed_bytes = total_size

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –ø–∞–ø–∫–∞–º
            categories = {}
            for file_path in moved_files:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø–æ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –ø–∞–ø–∫–µ
                parent = file_path.parent.name
                if parent != "_to_delete":
                    categories[parent] = categories.get(parent, 0) + 1

            cleanup_data["categories"] = categories
            self.stats.garbage_files_moved = len(moved_files)

        report["cleanup"] = cleanup_data

    def _analyze_created_documents(self, report: Dict[str, Any]) -> None:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã."""
        expected_docs = ["PROJECT_STRUCTURE.md", "MODULE_REGISTRY.md", "LLM_CONTEXT.md"]

        documents_data = {"expected": len(expected_docs), "created": 0, "details": {}}

        for doc_name in expected_docs:
            doc_path = self.project_root / doc_name
            doc_info = {"exists": doc_path.exists(), "size": 0, "lines": 0, "created_time": None}

            if doc_path.exists():
                documents_data["created"] += 1
                doc_info["size"] = doc_path.stat().st_size

                try:
                    content = doc_path.read_text(encoding="utf-8")
                    doc_info["lines"] = len(content.splitlines())
                except Exception:
                    doc_info["lines"] = 0

                # –í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è
                doc_info["created_time"] = datetime.fromtimestamp(
                    doc_path.stat().st_mtime
                ).isoformat()

            documents_data["details"][doc_name] = doc_info

        self.stats.documents_created = documents_data["created"]
        report["documents"] = documents_data

    def _analyze_project_structure(self, report: Dict[str, Any]) -> None:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç PROJECT_STRUCTURE.md."""
        doc_path = self.project_root / "PROJECT_STRUCTURE.md"

        structure_data = {
            "exists": doc_path.exists(),
            "directories_documented": 0,
            "entry_points_found": 0,
            "config_files_found": 0,
        }

        if doc_path.exists():
            try:
                content = doc_path.read_text(encoding="utf-8")

                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (—Å—Ç—Ä–æ–∫–∏ —Å ###)
                directories = len(re.findall(r"^###\s+", content, re.MULTILINE))
                structure_data["directories_documented"] = directories
                self.stats.directories_analyzed = directories

                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º entry points
                entry_points = len(re.findall(r"entry.?point", content, re.IGNORECASE))
                structure_data["entry_points_found"] = entry_points
                self.stats.entry_points_found = entry_points

                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                config_files = len(re.findall(r"\.(json|yaml|yml|ini|conf|toml)", content))
                structure_data["config_files_found"] = config_files
                self.stats.config_files_found = config_files

            except Exception as e:
                structure_data["error"] = str(e)

        report["structure"] = structure_data

    def _analyze_module_registry(self, report: Dict[str, Any]) -> None:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç MODULE_REGISTRY.md."""
        doc_path = self.project_root / "MODULE_REGISTRY.md"

        registry_data = {
            "exists": doc_path.exists(),
            "modules_documented": 0,
            "categories_found": 0,
            "categories": {},
        }

        if doc_path.exists():
            try:
                content = doc_path.read_text(encoding="utf-8")

                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –º–æ–¥—É–ª–∏ (–±–æ–ª–µ–µ –≥–∏–±–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)
                module_patterns = [
                    r"^##\s+.*\.py",  # ## module.py
                    r"^\*\*.*\.py\*\*",  # **module.py**
                    r"###\s+.*\.py",  # ### module.py
                ]

                modules = 0
                for pattern in module_patterns:
                    matches = re.findall(pattern, content, re.MULTILINE)
                    modules += len(matches)

                registry_data["modules_documented"] = modules
                self.stats.modules_analyzed = modules

                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (—Å—Ç—Ä–æ–∫–∏ —Å #, –Ω–æ –Ω–µ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞)
                categories = re.findall(r"^#\s+(.+)", content, re.MULTILINE)
                # –ò—Å–∫–ª—é—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –æ–±—â–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                categories = [
                    cat
                    for cat in categories
                    if not any(
                        word in cat.lower()
                        for word in ["module registry", "—Ä–µ–µ—Å—Ç—Ä –º–æ–¥—É–ª–µ–π", "overview", "–æ–±–∑–æ—Ä"]
                    )
                ]
                registry_data["categories_found"] = len(categories)
                self.stats.categories_found = len(categories)

                # –î–µ—Ç–∞–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                for category in categories:
                    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –º–æ–¥—É–ª–∏ –≤ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    category_pattern = rf"^#\s+{re.escape(category)}.*?(?=^#|\Z)"
                    category_section = re.search(
                        category_pattern, content, re.MULTILINE | re.DOTALL
                    )
                    if category_section:
                        category_content = category_section.group(0)
                        module_count = 0
                        for pattern in module_patterns:
                            matches = re.findall(pattern, category_content, re.MULTILINE)
                            module_count += len(matches)
                        registry_data["categories"][category] = module_count

            except Exception as e:
                registry_data["error"] = str(e)

        report["registry"] = registry_data

    def _create_summary(self, report: Dict[str, Any]) -> None:
        """–°–æ–∑–¥–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É."""
        summary = {
            "overall_success": True,
            "completed_stages": [],
            "issues": [],
            "recommendations": [],
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —ç—Ç–∞–ø –æ—á–∏—Å—Ç–∫–∏
        if report["cleanup"]["to_delete_exists"]:
            summary["completed_stages"].append("–û—á–∏—Å—Ç–∫–∞ –º—É—Å–æ—Ä–∞")
            if report["cleanup"]["moved_files"] == 0:
                summary["issues"].append("–§–∞–π–ª—ã –º—É—Å–æ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã")
        else:
            summary["issues"].append("–≠—Ç–∞–ø –æ—á–∏—Å—Ç–∫–∏ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω")
            summary["overall_success"] = False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        docs_created = report["documents"]["created"]
        docs_expected = report["documents"]["expected"]

        if docs_created == docs_expected:
            summary["completed_stages"].append("–°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏")
        else:
            summary["issues"].append(f"–°–æ–∑–¥–∞–Ω–æ {docs_created} –∏–∑ {docs_expected} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            summary["overall_success"] = False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if report.get("structure", {}).get("exists"):
            summary["completed_stages"].append("–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞")
        else:
            summary["issues"].append("PROJECT_STRUCTURE.md –Ω–µ —Å–æ–∑–¥–∞–Ω")
            summary["overall_success"] = False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–µ—Å—Ç—Ä –º–æ–¥—É–ª–µ–π
        if report.get("registry", {}).get("exists"):
            summary["completed_stages"].append("–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–µ—Å—Ç—Ä–∞ –º–æ–¥—É–ª–µ–π")
        else:
            summary["issues"].append("MODULE_REGISTRY.md –Ω–µ —Å–æ–∑–¥–∞–Ω")
            summary["overall_success"] = False

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if self.stats.modules_analyzed > 100:
            summary["recommendations"].append("–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö –º–æ–¥—É–ª–µ–π")

        if self.stats.categories_found < 5:
            summary["recommendations"].append("–í–æ–∑–º–æ–∂–Ω–æ —Å—Ç–æ–∏—Ç –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é –º–æ–¥—É–ª–µ–π")

        if report["cleanup"]["moved_files"] > 200:
            summary["recommendations"].append("–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏")

        report["summary"] = summary
        report["stats"] = asdict(self.stats)

    def save_report(self, report: Dict[str, Any], filename: str = None) -> Path:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –≤ —Ñ–∞–π–ª.

        Args:
            report: –î–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç–∞
            filename: –ò–º—è —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)

        Returns:
            –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"refactoring_report_{timestamp}.json"

        report_path = self.project_root / filename

        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        return report_path

    def print_report(self, report: Dict[str, Any]) -> None:
        """–í—ã–≤–æ–¥–∏—Ç –æ—Ç—á–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å."""
        print("=" * 60)
        print("–ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ì–õ–û–ë–ê–õ–¨–ù–û–ì–û –†–ï–§–ê–ö–¢–û–†–ò–ù–ì–ê")
        print("=" * 60)

        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"–ü—Ä–æ–µ–∫—Ç: {report['project_root']}")
        print(f"–í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {report['timestamp']}")
        print()

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = report["stats"]
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"  –§–∞–π–ª–æ–≤ –º—É—Å–æ—Ä–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ: {stats['garbage_files_moved']}")
        print(f"  –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ –º–µ—Å—Ç–∞: {self._format_size(stats['size_freed_bytes'])}")
        print(f"  –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {stats['directories_analyzed']}")
        print(f"  Entry points –Ω–∞–π–¥–µ–Ω–æ: {stats['entry_points_found']}")
        print(f"  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {stats['config_files_found']}")
        print(f"  –ú–æ–¥—É–ª–µ–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {stats['modules_analyzed']}")
        print(f"  –ö–∞—Ç–µ–≥–æ—Ä–∏–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞: {stats['categories_found']}")
        print(f"  –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {stats['documents_created']}")
        print()

        # –°–æ–∑–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        print("üìÑ –°–û–ó–î–ê–ù–ù–´–ï –î–û–ö–£–ú–ï–ù–¢–´:")
        for doc_name, doc_info in report["documents"]["details"].items():
            status = "‚úÖ" if doc_info["exists"] else "‚ùå"
            print(f"  {status} {doc_name}")
            if doc_info["exists"]:
                print(f"      –†–∞–∑–º–µ—Ä: {self._format_size(doc_info['size'])}")
                print(f"      –°—Ç—Ä–æ–∫: {doc_info['lines']}")
        print()

        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –º–æ–¥—É–ª–µ–π
        if report.get("registry", {}).get("categories"):
            print("üè∑Ô∏è  –ö–ê–¢–ï–ì–û–†–ò–ò –ú–û–î–£–õ–ï–ô:")
            for category, count in report["registry"]["categories"].items():
                print(f"  {category}: {count} –º–æ–¥—É–ª–µ–π")
            print()

        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—á–∏—Å—Ç–∫–∏
        if report["cleanup"]["categories"]:
            print("üßπ –û–ß–ò–°–¢–ö–ê –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
            for category, count in report["cleanup"]["categories"].items():
                print(f"  {category}: {count} —Ñ–∞–π–ª–æ–≤")
            print()

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
        summary = report["summary"]
        print("üìã –°–í–û–î–ö–ê:")
        print(f"  –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {'‚úÖ –£–°–ü–ï–•' if summary['overall_success'] else '‚ùå –ü–†–û–ë–õ–ï–ú–´'}")
        print(f"  –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã: {len(summary['completed_stages'])}")
        for stage in summary["completed_stages"]:
            print(f"    ‚úÖ {stage}")

        if summary["issues"]:
            print(f"  –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã: {len(summary['issues'])}")
            for issue in summary["issues"]:
                print(f"    ‚ùå {issue}")

        if summary["recommendations"]:
            print(f"  –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {len(summary['recommendations'])}")
            for rec in summary["recommendations"]:
                print(f"    üí° {rec}")

        print("=" * 60)

    def _format_size(self, size_bytes: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥."""
        for unit in ["B", "KB", "MB", "GB"]:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} TB"


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ä–µ–ø–æ—Ä—Ç–µ—Ä–∞."""
    import argparse

    parser = argparse.ArgumentParser(
        description="–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ –≥–ª–æ–±–∞–ª—å–Ω–æ–º —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–µ"
    )

    parser.add_argument(
        "--project-root",
        type=Path,
        help="–ü—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è)",
    )

    parser.add_argument("--save", action="store_true", help="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç –≤ JSON —Ñ–∞–π–ª")

    parser.add_argument("--output", type=str, help="–ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞")

    args = parser.parse_args()

    try:
        reporter = RefactoringReporter(project_root=args.project_root)
        report = reporter.generate_report()

        # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å
        reporter.print_report(report)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if args.save:
            report_path = reporter.save_report(report, args.output)
            print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
