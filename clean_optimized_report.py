#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–î–∏—Å—Ç–∏–ª–ª—è—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤ - –û—á–∏—Å—Ç–∫–∞ –æ—Ç –ª–∏—à–Ω–µ–≥–æ –º—É—Å–æ—Ä–∞
–£–¥–∞–ª—è–µ—Ç 86.7% —à—É–º–∞ –∏–∑ real_usage_patterns –∏ –¥—Ä—É–≥–∏—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —É–∫–∞–∑–∞–Ω–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ –∏ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–æ–≤
"""

import json
import argparse
import sys
from pathlib import Path

def clean_optimized_report(input_path, output_path):
    """–û—á–∏—â–∞–µ—Ç –æ—Ç—á–µ—Ç –æ—Ç –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    input_path = Path(input_path)
    output_path = Path(output_path)
    
    if not input_path.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
        return None
    
    print(f"üì• –ó–∞–≥—Ä—É–∂–∞—é –æ—Ç—á–µ—Ç –∏–∑: {input_path}")
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON —Ñ–∞–π–ª: {e}")
        return None
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return None
    
    original_size = len(str(data))
    print(f"üìä –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {original_size} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    total_removed_items = 0
    
    # 1. –û—á–∏—â–∞–µ–º real_usage_patterns (–æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ —à—É–º–∞)
    if 'real_usage_patterns' in data:
        original_calls = data['real_usage_patterns'].get('method_calls', [])
        if original_calls:
            print(f"üóëÔ∏è  –ù–∞–π–¥–µ–Ω–æ –≤—ã–∑–æ–≤–æ–≤ –º–µ—Ç–æ–¥–æ–≤: {len(original_calls)}")
            
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤—ã–∑–æ–≤—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å —Ü–µ–ª–µ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
            target_files = [
                'attack_dispatcher.py',
                'core/bypass/engine/attack_dispatcher.py', 
                'attack_dispatcher_backup.py',
                'attack_dispatcher_refactored.py'
            ]
            
            cleaned_calls = []
            removed_count = 0
            
            for call in original_calls:
                file_path = call.get('file', '').lower()
                is_target = any(target_file in file_path for target_file in target_files)
                
                if is_target:
                    cleaned_calls.append(call)
                else:
                    removed_count += 1
            
            print(f"‚úÖ –û—Å—Ç–∞–≤–ª–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤: {len(cleaned_calls)}")
            print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ —à—É–º–∞: {removed_count} –≤—ã–∑–æ–≤–æ–≤ ({removed_count/len(original_calls)*100:.1f}%)")
            
            # –ó–∞–º–µ–Ω—è–µ–º –º–∞—Å—Å–∏–≤ –≤—ã–∑–æ–≤–æ–≤ –Ω–∞ –æ—á–∏—â–µ–Ω–Ω—ã–π
            data['real_usage_patterns']['method_calls'] = cleaned_calls
            total_removed_items += removed_count
    
    # 2. –û—á–∏—â–∞–µ–º modules (–¥–ª—è —Ñ–∞–π–ª–æ–≤ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞)
    if 'modules' in data and isinstance(data['modules'], dict):
        original_modules = len(data['modules'])
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –º–æ–¥—É–ª–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å —Ü–µ–ª–µ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
        target_modules = {}
        removed_modules = 0
        
        for module_path, module_info in data['modules'].items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–≤—è–∑–∞–Ω –ª–∏ –º–æ–¥—É–ª—å —Å attack_dispatcher
            is_relevant = (
                'attack_dispatcher' in module_path.lower() or
                'bypass' in module_path.lower() or
                'engine' in module_path.lower() or
                any(cls.get('name', '').lower().find('attack') != -1 
                    for cls in module_info.get('classes', [])) or
                any(func.get('name', '').lower().find('attack') != -1 
                    for func in module_info.get('functions', []))
            )
            
            if is_relevant:
                target_modules[module_path] = module_info
            else:
                removed_modules += 1
        
        if removed_modules > 0:
            print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –º–æ–¥—É–ª–µ–π: {removed_modules} –∏–∑ {original_modules} ({removed_modules/original_modules*100:.1f}%)")
            data['modules'] = target_modules
            total_removed_items += removed_modules
    
    # 3. –û—á–∏—â–∞–µ–º functions (–≥–ª–æ–±–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏)
    if 'functions' in data and isinstance(data['functions'], dict):
        original_functions = len(data['functions'])
        target_functions = {}
        removed_functions = 0
        
        for func_key, func_info in data['functions'].items():
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ñ—É–Ω–∫—Ü–∏–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å attack_dispatcher
            is_relevant = (
                'attack' in func_key.lower() or
                'dispatch' in func_key.lower() or
                'bypass' in func_key.lower() or
                'attack' in func_info.get('name', '').lower()
            )
            
            if is_relevant:
                target_functions[func_key] = func_info
            else:
                removed_functions += 1
        
        if removed_functions > 0:
            print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π: {removed_functions} –∏–∑ {original_functions} ({removed_functions/original_functions*100:.1f}%)")
            data['functions'] = target_functions
            total_removed_items += removed_functions
    
    # 4. –û—á–∏—â–∞–µ–º classes (–≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã)
    if 'classes' in data and isinstance(data['classes'], dict):
        original_classes = len(data['classes'])
        target_classes = {}
        removed_classes = 0
        
        for cls_key, cls_info in data['classes'].items():
            # –û—Å—Ç–∞–≤–ª—è–µ–º –∫–ª–∞—Å—Å—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å attack_dispatcher
            is_relevant = (
                'attack' in cls_key.lower() or
                'dispatch' in cls_key.lower() or
                'bypass' in cls_key.lower() or
                'attack' in cls_info.get('name', '').lower()
            )
            
            if is_relevant:
                target_classes[cls_key] = cls_info
            else:
                removed_classes += 1
        
        if removed_classes > 0:
            print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤: {removed_classes} –∏–∑ {original_classes} ({removed_classes/original_classes*100:.1f}%)")
            data['classes'] = target_classes
            total_removed_items += removed_classes
    
    # 5. –û—á–∏—â–∞–µ–º API contracts –æ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    if 'api_contracts' in data:
        contracts = data['api_contracts']
        if isinstance(contracts, dict):
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, –µ—Å–ª–∏ –µ—Å—Ç—å
            unique_contracts = {}
            for key, value in contracts.items():
                if key not in unique_contracts:
                    unique_contracts[key] = value
            if len(unique_contracts) != len(contracts):
                removed_duplicates = len(contracts) - len(unique_contracts)
                print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ API contracts: {removed_duplicates}")
                data['api_contracts'] = unique_contracts
                total_removed_items += removed_duplicates
    
    # 6. –£–¥–∞–ª—è–µ–º –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata_removed = 0
    for section_name in ['dependencies', 'dead_code', 'feature_clusters']:
        if section_name in data:
            section_data = data[section_name]
            if isinstance(section_data, dict):
                # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏/–º–µ—Ä—Ç–≤—ã–π –∫–æ–¥
                if section_name == 'dependencies':
                    original_deps = len(section_data)
                    relevant_deps = {k: v for k, v in section_data.items() 
                                   if 'attack' in k.lower() or 'dispatch' in k.lower() or 'bypass' in k.lower()}
                    if len(relevant_deps) < original_deps:
                        removed = original_deps - len(relevant_deps)
                        print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: {removed}")
                        data[section_name] = relevant_deps
                        metadata_removed += removed
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
    print(f"üì§ –°–æ—Ö—Ä–∞–Ω—è—é –æ—á–∏—â–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –≤: {output_path}")
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    try:
        with open(output_path, 'r', encoding='utf-8') as f:
            cleaned_data = json.load(f)
        
        new_size = len(str(cleaned_data))
        
        print(f"üìä –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {new_size} —Å–∏–º–≤–æ–ª–æ–≤")
        if original_size > 0:
            compression_ratio = (1 - new_size/original_size) * 100
            print(f"üìâ –°–∂–∞—Ç–∏–µ: {compression_ratio:.1f}%")
        
        if total_removed_items > 0:
            print(f"üéØ –í—Å–µ–≥–æ —É–¥–∞–ª–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {total_removed_items}")
        
        return output_path
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
        return None

def analyze_cleaned_report(report_path):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç"""
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –û–ß–ò–©–ï–ù–ù–û–ì–û –û–¢–ß–ï–¢–ê")
    print("=" * 50)
    
    try:
        with open(report_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞: {e}")
        return
    
    print("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç—á–µ—Ç–∞:")
    for section, content in data.items():
        if isinstance(content, dict):
            size = len(str(content))
            items = len(content) if hasattr(content, '__len__') else 'N/A'
            print(f"  {section}: {items} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ ({size} —Å–∏–º–≤–æ–ª–æ–≤)")
        elif isinstance(content, list):
            size = len(str(content))
            print(f"  {section}: {len(content)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ ({size} —Å–∏–º–≤–æ–ª–æ–≤)")
    
    # –ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
    if 'real_usage_patterns' in data:
        patterns = data['real_usage_patterns']
        print(f"\nüéØ Real Usage Patterns:")
        for key, value in patterns.items():
            if isinstance(value, list):
                print(f"  {key}: {len(value)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            else:
                print(f"  {key}: {type(value).__name__}")
    
    if 'api_contracts' in data:
        contracts = data['api_contracts']
        print(f"\nüîó API Contracts:")
        if isinstance(contracts, dict):
            for key in contracts.keys():
                print(f"  - {key}")

def generate_default_output_path(input_path):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—É—Ç—å –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
    input_path = Path(input_path)
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    stem = input_path.stem
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—É—Ñ—Ñ–∏–∫—Å _distilled
    new_stem = f"{stem}_distilled"
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø—É—Ç—å –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    output_path = input_path.parent / f"{new_stem}{input_path.suffix}"
    
    return output_path

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(
        description="–î–∏—Å—Ç–∏–ª–ª—è—Ç–æ—Ä –æ—Ç—á–µ—Ç–æ–≤ - –æ—á–∏—Å—Ç–∫–∞ –æ—Ç –ª–∏—à–Ω–µ–≥–æ –º—É—Å–æ—Ä–∞",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (–≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª —Å–æ–∑–¥–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
  python clean_optimized_report.py input_report.json
  
  # –£–∫–∞–∑–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
  python clean_optimized_report.py input_report.json -o cleaned_report.json
  
  # –ü–æ–ª–Ω—ã–µ –ø—É—Ç–∏
  python clean_optimized_report.py C:\\path\\to\\report.json -o C:\\path\\to\\cleaned.json
  
  # –ë–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
  python clean_optimized_report.py input_report.json --no-analysis
        """,
    )

    parser.add_argument(
        "input_file", 
        help="–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É JSON —Ñ–∞–π–ª—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
    )
    
    parser.add_argument(
        "-o", "--output", 
        help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: <input_file>_distilled.json –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏)"
    )
    
    parser.add_argument(
        "--no-analysis", 
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"
    )

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    input_path = Path(args.input_file)
    if not input_path.exists():
        print(f"‚ùå –û—à–∏–±–∫–∞: –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
        sys.exit(1)

    if not input_path.is_file():
        print(f"‚ùå –û—à–∏–±–∫–∞: –£–∫–∞–∑–∞–Ω–Ω—ã–π –ø—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ñ–∞–π–ª–æ–º: {input_path}")
        sys.exit(1)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = generate_default_output_path(input_path)

    print("=" * 80)
    print("–î–ò–°–¢–ò–õ–õ–Ø–¢–û–† –û–¢–ß–ï–¢–û–í - –û–ß–ò–°–¢–ö–ê –û–¢ –ú–£–°–û–†–ê")
    print("=" * 80)
    print(f"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {input_path}")
    print(f"–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_path}")
    print("–£–¥–∞–ª—è–µ—Ç –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç—á–µ—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞")
    print("=" * 80)

    # –û—á–∏—â–∞–µ–º –æ—Ç—á–µ—Ç
    cleaned_path = clean_optimized_report(input_path, output_path)

    if cleaned_path is None:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª")
        sys.exit(1)

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–µ—Å–ª–∏ –Ω–µ –æ—Ç–∫–ª—é—á–µ–Ω)
    if not args.no_analysis:
        analyze_cleaned_report(cleaned_path)

    print(f"\n‚úÖ –î–ò–°–¢–ò–õ–õ–Ø–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
    print("=" * 80)
    print(f"üìÅ –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {input_path}")
    print(f"üìÅ –î–∏—Å—Ç–∏–ª–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª: {cleaned_path}")
    print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ —É–º–µ–Ω—å—à–µ–Ω, —à—É–º —É–¥–∞–ª–µ–Ω")
    
    sys.exit(0)

if __name__ == '__main__':
    # –ï—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø—Ä–∞–≤–∫—É
    if len(sys.argv) == 1:
        print("=" * 80)
        print("–î–ò–°–¢–ò–õ–õ–Ø–¢–û–† –û–¢–ß–ï–¢–û–í")
        print("=" * 80)
        print("–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
        print("python clean_optimized_report.py --help")
        print()
        print("–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç:")
        print("python clean_optimized_report.py your_report.json")
        sys.exit(0)
    
    main()
